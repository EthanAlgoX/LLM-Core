# Level 4 测试题（PPO / GRPO / RLHF）

1. PPO 的“clip”思想本质是在限制什么？
2. GRPO 的组内相对奖励为什么能减小尺度敏感问题？
3. RLHF 完整流程为什么通常先做 SFT？
4. KL 约束在对齐训练中起什么作用？
5. 奖励模型被“投机取巧”时会出现什么现象，如何缓解？
