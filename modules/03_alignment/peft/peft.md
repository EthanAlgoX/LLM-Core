# é«˜æ•ˆå¾®è°ƒ (PEFT: Parameter-Efficient Fine-Tuning)

> [!TIP]
> **ä¸€å¥è¯é€šä¿—ç†è§£**ï¼šåªæ”¹æ¨¡å‹ä¸€å°éƒ¨åˆ†æƒé‡ï¼Œå°±èƒ½è®©å®ƒå­¦ä¼šæ–°æŠ€èƒ½ï¼Œçœæ—¶çœæ˜¾å­˜

## å®šä½ä¸åˆ†ç±»

- **é˜¶æ®µ**ï¼šåè®­ç»ƒå¯¹é½ / å¾®è°ƒä¼˜åŒ–ã€‚
- **ç±»å‹**ï¼šè½»é‡åŒ–å¾®è°ƒæŠ€æœ¯ã€‚
- **ä½œç”¨**ï¼šPEFT æ—¨åœ¨ä»…è®­ç»ƒæå°‘é‡å‚æ•°ï¼Œåœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ä¸Šå®ç°ä¸‹æ¸¸ä»»åŠ¡é€‚é…ã€‚LoRA æ˜¯æŠ€æœ¯è§£æä¸­å‡ ä¹å¿…è€ƒçš„é«˜é¢‘è€ƒç‚¹ã€‚

## æ ¸å¿ƒç®—æ³•ï¼šLoRA (Low-Rank Adaptation)

### æ ¸å¿ƒæ€æƒ³

å‡è®¾æ¨¡å‹æƒé‡çš„æ›´æ–°é‡ $\Delta W$ æ˜¯ **ä½ç§© (Low-Rank)** çš„ã€‚
æˆ‘ä»¬å¯ä»¥å°† $\Delta W$ åˆ†è§£ä¸ºä¸¤ä¸ªæå°çš„çŸ©é˜µç›¸ä¹˜ï¼š

$$\Delta W = A \times B$$

- å…¶ä¸­ $W \in \mathbb{R}^{d \times k}$ï¼Œ$A \in \mathbb{R}^{d \times r}$ï¼Œ$B \in \mathbb{R}^{r \times k}$ï¼Œç§© $r \ll d, k$ã€‚

### è®­ç»ƒä¸æ¨ç†

1. **è®­ç»ƒé˜¶æ®µ**ï¼šå†»ç»“åŸå§‹æƒé‡ $W$ï¼Œä»…è®­ç»ƒ $A$ å’Œ $B$ã€‚
2. **æ¨ç†é˜¶æ®µ**ï¼šå°† $A \times B$ é‡æ–°åˆå¹¶å› $W$ ï¼ˆå³ $W_{new} = W + AB$ ï¼‰ï¼Œå› æ­¤**æ¨ç†å»¶è¿Ÿä¸ºé›¶**ã€‚

### ä¸ºä»€ä¹ˆ LoRA æ˜¾å­˜å ç”¨ä½ï¼Ÿ

å› ä¸ºå®ƒä¸å­˜å‚¨åºå¤§çš„æ¢¯åº¦çŸ©é˜µ $\Delta W$ ï¼Œä»…å­˜å‚¨ç»†å°çš„ $A$ å’Œ $B$ ã€‚

## è¿›é˜¶ï¼šQLoRA (Quantized LoRA)

### QLoRA æŠ€æœ¯äº®ç‚¹

1. **4-bit NormalFloat (NF4)**ï¼šä¸“é—¨ä¸ºæ­£æ€åˆ†å¸ƒæƒé‡è®¾è®¡çš„é‡åŒ–æ ¼å¼ï¼Œæ¯” 4-bit Float ç²¾åº¦æ›´é«˜ã€‚
2. **Double Quantization**ï¼šå¯¹é‡åŒ–å¸¸æ•°æœ¬èº«å†è¿›è¡Œä¸€æ¬¡é‡åŒ–ï¼ŒèŠ‚çœé¢å¤–çš„å‡ ç™¾ MB æ˜¾å­˜ã€‚
3. **Paged Optimizers**ï¼šå°†ä¼˜åŒ–å™¨çŠ¶æ€åœ¨æ˜¾å­˜å’Œå†…å­˜ä¹‹é—´è‡ªåŠ¨åˆ‡æ¢ï¼Œé˜²æ­¢ OOMã€‚

## å…¶ä»–è½»é‡åŒ–æŠ€æœ¯

### 1. Prefix Tuning

- **æ ¸å¿ƒé€»è¾‘**ï¼šåœ¨è¾“å…¥ Token å‰æ‹¼æ¥ä¸€ç»„å¯è®­ç»ƒçš„ **Virtual Tokens (Prefix)**ã€‚
- **ä¸ LoRA åŒºåˆ«**ï¼š
  - **Prefix Tuning**ï¼šæ”¹å˜çš„æ˜¯è¾“å…¥ Hidden Stateï¼Œå¢åŠ äº†ä¸€å®šçš„æ¨ç†è®¡ç®—é‡ã€‚
  - **LoRA**ï¼šæ”¹å˜çš„æ˜¯æƒé‡ $W$ï¼Œå¯ç›´æ¥åˆå¹¶ï¼Œæ¨ç†é›¶é¢å¤–å¼€é”€ã€‚

### 2. P-Tuning / Prompt Tuning

- ä»…åœ¨ Embedding å±‚å¢åŠ å¯è®­ç»ƒå‘é‡ï¼Œé€‚ç”¨äºä»»åŠ¡æŒ‡ä»¤æå…¶æ˜ç¡®çš„åœºæ™¯ã€‚

## çŸ¥è¯†è’¸é¦ (Knowledge Distillation)

### è’¸é¦æŠ€æœ¯äº®ç‚¹

- **Teacher-Student æ¶æ„**ï¼šå¤§æ¨¡å‹ (Teacher) å¼•å¯¼å°æ¨¡å‹ (Student) å­¦ä¹ ã€‚
- **Logits è’¸é¦**ï¼šStudent æ‹Ÿåˆ Teacher è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒã€‚
- **èƒ½åŠ›æå–**ï¼šå¸¸ç”¨äºå°† 175B æ¨¡å‹çš„å¤æ‚é€»è¾‘è’¸é¦åˆ° 7B æ¨¡å‹ä¸­ï¼Œæå‡ç«¯ä¾§æ‰§è¡Œé€Ÿåº¦ã€‚

## æŠ€æœ¯æ ¸å¿ƒè§£æ

1. LoRA çš„ $r$ ï¼ˆç§©ï¼‰é€‰å¤šå°‘åˆé€‚ï¼Ÿ
   - é€šå¸¸ 8 æˆ– 16 å·²ç»è¶³å¤Ÿã€‚è¿‡å¤§çš„ $r$ ä¼šå¢åŠ æ˜¾å­˜ä½†å¹¶ä¸ä¸€å®šä¼šæå‡ç²¾åº¦ã€‚
2. LoRA ä¸å…¨å‚å¾®è°ƒçš„æ”¶æ•›é€Ÿåº¦ï¼Ÿ
   - LoRA æ”¶æ•›é€šå¸¸æ›´å¿«ï¼Œå› ä¸ºå®ƒä¼˜åŒ–çš„æ˜¯ä½ç§©æ®‹å·®ï¼Œæ›´å®¹æ˜“åœ¨å±€éƒ¨æœç´¢åˆ°æœ€ä¼˜è§£ã€‚
3. PEFT åœ¨å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„åº”ç”¨ï¼Ÿ
   - å¸¸ç”¨äºå›ºå®š ViT ç¼–ç å™¨ï¼Œä»…å¯¹ Projector æˆ– LLM éƒ¨åˆ†è¿›è¡Œ LoRA å¾®è°ƒï¼Œå®ç°è·¨æ¨¡æ€å¯¹é½ã€‚

---

## ğŸ› ï¸ å·¥ç¨‹å®æˆ˜

### æ–¹å¼ä¸€ï¼šPEFT åº“ï¼ˆHuggingFace åŸç”Ÿï¼‰

```python
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForCausalLM, AutoTokenizer

# 1. åŠ è½½åŸºåº§æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B", device_map="auto")

# 2. å®šä¹‰ LoRA é…ç½®
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=64,                          # ç§©ï¼ˆæ¨è 8~64ï¼‰
    lora_alpha=128,                # ç¼©æ”¾ç³»æ•°ï¼Œé€šå¸¸ = 2 Ã— r
    lora_dropout=0.05,
    target_modules="all-linear",   # å¯¹æ‰€æœ‰çº¿æ€§å±‚æ³¨å…¥ LoRA
)

# 3. åŒ…è£…æ¨¡å‹
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
# è¾“å‡ºç¤ºä¾‹ï¼štrainable params: 83,886,080 || all params: 7,699,726,336 || trainable%: 1.089%
```

### æ–¹å¼äºŒï¼šQLoRAï¼ˆ4-bit é‡åŒ– + LoRAï¼‰

```python
from transformers import BitsAndBytesConfig
import torch

# 4-bit é‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",          # NormalFloat4ï¼Œç²¾åº¦ä¼˜äº FP4
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,     # äºŒæ¬¡é‡åŒ–ï¼Œå†çœå‡ ç™¾ MB
)

model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B",
    quantization_config=bnb_config,
    device_map="auto",
)

# ç„¶ååŒæ ·ä½¿ç”¨ get_peft_model åŒ…è£…
model = get_peft_model(model, lora_config)
# QLoRA: 7B æ¨¡å‹ä»…éœ€ ~6GB VRAM
```

### æ–¹å¼ä¸‰ï¼šLLaMA Factory ä¸€é”®å¾®è°ƒ

```yaml
# peft_lora.yaml
model_name_or_path: Qwen/Qwen2.5-7B
finetuning_type: lora              # æˆ– qloraï¼ˆè‡ªåŠ¨å¯ç”¨ 4-bitï¼‰
quantization_bit: 4                # å¯ç”¨ QLoRA
lora_rank: 64
lora_target: all
stage: sft
dataset: my_custom_sft
template: qwen
output_dir: saves/qwen2.5-7b/qlora
```

```bash
llamafactory-cli train peft_lora.yaml
```

### LoRA æƒé‡åˆå¹¶ä¸å¯¼å‡º

```python
from peft import PeftModel

# åŠ è½½åŸºåº§ + LoRA adapter
base_model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B")
model = PeftModel.from_pretrained(base_model, "saves/qwen2.5-7b/qlora")

# åˆå¹¶æƒé‡ï¼ˆæ¨ç†é›¶å»¶è¿Ÿï¼‰
merged_model = model.merge_and_unload()
merged_model.save_pretrained("models/qwen2.5-7b-merged")
```
