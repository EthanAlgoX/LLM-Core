# SFT (Supervised Fine-Tuning) ç›‘ç£å¾®è°ƒ

> [!TIP]
> **ä¸€å¥è¯é€šä¿—ç†è§£**ï¼šæ‹¿äººç±»å†™çš„é«˜è´¨é‡é—®ç­”å¯¹ï¼Œæ‰‹æŠŠæ‰‹æ•™æ¨¡å‹"æ€ä¹ˆè¯´è¯"

## å®šä½ä¸åˆ†ç±»

- **é˜¶æ®µ**ï¼šåè®­ç»ƒï¼ˆPost-trainingï¼‰ä¹‹å¯¹é½èµ·ç‚¹ã€‚
- **ç±»å‹**ï¼šç›‘ç£å­¦ä¹ ï¼ˆSupervised Learningï¼‰ã€‚
- **ä½œç”¨**ï¼šå°†é¢„è®­ç»ƒåŸºåº§æ¨¡å‹ï¼ˆBase Modelï¼‰è½¬åŒ–ä¸ºèƒ½å¤Ÿéµå¾ªäººç±»æŒ‡ä»¤ï¼ˆInstruction Followingï¼‰çš„å¯¹è¯æ¨¡å‹ï¼ˆChat Modelï¼‰ã€‚å®ƒæ˜¯ RLHF æµç¨‹çš„ç‰©ç†åŸºç¡€ã€‚

## æ¨¡å‹è®­ç»ƒçš„å…³é”®æ­¥éª¤

SFT å¤„ç†æµç¨‹éµå¾ªä»¥ä¸‹æ ¸å¿ƒæ­¥éª¤ï¼š

1. **æ•°æ®åˆ†è¯ (Tokenization)**ï¼šå°†æŒ‡ä»¤ï¼ˆInstructionï¼‰ä¸å›ç­”ï¼ˆOutputï¼‰æ‹¼æ¥ï¼Œå¹¶è½¬æ¢ä¸ºæ¨¡å‹å¯è¯»çš„ Token IDsã€‚
2. **æ©ç å¤„ç† (Label Masking)**ï¼šåœ¨è®¡ç®—æŸå¤±æ—¶ï¼Œé€šå¸¸å°†æŒ‡ä»¤éƒ¨åˆ†çš„æ ‡ç­¾ç½®ä¸º `-100`ï¼ˆå¿½ç•¥ï¼‰ï¼Œç¡®ä¿æ¨¡å‹ä»…å­¦ä¹ å¦‚ä½•ç”Ÿæˆå›ç­”ï¼Œè€Œä¸å»å­¦å¦‚ä½•å¤è¿°æŒ‡ä»¤ã€‚
3. **å‰å‘ä¼ æ’­ (Forward Pass)**ï¼šæ¨¡å‹æ ¹æ® Prompt é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼ˆTokenï¼‰çš„æ¦‚ç‡åˆ†å¸ƒã€‚
4. **æŸå¤±è®¡ç®— (Loss Calculation)**ï¼šä½¿ç”¨**äº¤å‰ç†µï¼ˆCross-Entropyï¼‰**å¯¹æ¯”é¢„æµ‹å€¼ä¸æ ‡å‡†ç­”æ¡ˆã€‚
5. **åå‘ä¼ æ’­ä¸ä¼˜åŒ– (Backprop & Update)**ï¼šæ ¹æ®æ¢¯åº¦æ›´æ–°æ¨¡å‹æƒé‡ï¼ˆæˆ– LoRA æƒé‡ï¼‰ã€‚

## æ ¸å¿ƒåŸç†ä¸æŸå¤±å‡½æ•°

### 1. å…³é”®å…¬å¼ï¼šäº¤å‰ç†µæŸå¤± (Cross-Entropy Loss)

SFT çš„æœ¬è´¨æ˜¯**æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰**ï¼Œå…¶æ ¸å¿ƒæ•°å­¦ç›®æ ‡æ˜¯æœ€å°åŒ–å›ç­”åºåˆ—çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼š

$$L(\theta) = - \sum_{i=1}^{T} \log P_\theta(y_i | x, y_{1}, \dots, y_{i-1})$$

**å…¬å¼æ‹†è§£ä¸ç†è§£ï¼š**

- **$x$ (Input)**ï¼šè¾“å…¥çš„æŒ‡ä»¤å†…å®¹ï¼ˆPromptï¼‰ã€‚
- **$y_i$ (Target)**ï¼šæ ‡å‡†ç­”æ¡ˆä¸­ç¬¬ $i$ ä¸ªä½ç½®çš„è¯ï¼ˆTokenï¼‰ã€‚
- **$P_\theta(\dots)$**ï¼šæ¨¡å‹æ ¹æ®å½“å‰å‚æ•° $\theta$ï¼Œåœ¨å·²çŸ¥æŒ‡ä»¤å’Œå‰åºæ–‡å­—çš„å‰æä¸‹ï¼Œé¢„æµ‹å‡ºæ­£ç¡®ä¸‹ä¸€ä¸ªè¯çš„â€œæ¦‚ç‡â€ã€‚
- **$\log$ ä¸è´Ÿå·**ï¼šå°†æ¦‚ç‡è½¬åŒ–ä¸ºæŸå¤±å€¼ã€‚æ¦‚ç‡è¶Šå¤§ï¼ˆé¢„æµ‹è¶Šå‡†ï¼‰ï¼Œ $\log$ è¶Šæ¥è¿‘ 0ï¼ŒæŸå¤±å€¼è¶Šå°ã€‚

### 2. æ·±åº¦è§£è¯»ï¼šå¦‚ä½•ç›´è§‚ç†è§£è¿™ä¸ªè¿‡ç¨‹ï¼Ÿ

- **é€è¯å¯¹é½ (Token-level Alignment)**ï¼šæ¨¡å‹åœ¨æ¯ä¸€ä¸ªæ­¥é•¿ä¸Šéƒ½åœ¨å°è¯•é¢„æµ‹â€œä¸‹ä¸€ä¸ªè¯â€ã€‚å®ƒåœ¨å­¦ä¹ æ ‡å‡†ç­”æ¡ˆä¸­è¯ä¸è¯ä¹‹é—´çš„ç»Ÿè®¡è§„å¾‹ã€‚
- **Teacher Forcing (å¼ºåˆ¶çº å)**ï¼šè¿™æ˜¯ SFT çš„å…³é”®ç‰¹å¾ã€‚åœ¨è®­ç»ƒå‰å‘ä¼ æ’­æ—¶ï¼Œæ— è®ºæ¨¡å‹é¢„æµ‹å‡ºçš„ä¸Šä¸€ä¸ªè¯æ˜¯å¦æ­£ç¡®ï¼Œæ¨¡å‹åœ¨è®¡ç®—å½“å‰è¯æ—¶è¾“å…¥çš„æ°¸è¿œæ˜¯**çœŸå®ç­”æ¡ˆ**ä¸­çš„å‰æ–‡ã€‚å°±åƒè€å¸ˆç‰µç€æ‰‹å†™å­—ï¼Œé”™äº†ä¸€ç¬”ç«‹å³æ‹‰å›ã€‚
- **æ¦‚ç‡æœ€å¤§åŒ–**ï¼šå…¬å¼çš„ç»ˆæç›®çš„æ˜¯è®©æ¨¡å‹åœ¨çœ‹åˆ°ç‰¹å®šæŒ‡ä»¤æ—¶ï¼Œèƒ½å¤Ÿä»¥â€œæœ€å¤§æ¦‚ç‡â€åå‡ºæ•°æ®é›†é‡Œçš„æ ‡å‡†å­—å¥ã€‚

### 3. ä¸ PPO/GRPO çš„æœ¬è´¨åŒºåˆ«

| ç‰¹æ€§ | SFT (ç›‘ç£å¾®è°ƒ) | RL (PPO/GRPO) |
| :--- | :--- | :--- |
| **å­¦ä¹ æº** | **é™æ€æ ‡ç­¾**ï¼ˆOutput å­—å¯¹å­—æ¨¡ä»¿ï¼‰ã€‚ | **åŠ¨æ€åé¦ˆ**ï¼ˆReward æ‰“åˆ†é©±åŠ¨ï¼‰ã€‚ |
| **çµæ´»æ€§** | ä½ã€‚æ¨¡å‹è¢«é™åˆ¶åœ¨æ¨¡ä»¿æ•°æ®é›†ã€‚ | é«˜ã€‚æ¨¡å‹å¯ä»¥æ¢ç´¢æ•°æ®é›†ä¹‹å¤–æ›´å¥½çš„è§£ã€‚ |
| **ç¨³å®šæ€§** | æé«˜ã€‚æœ€ç®€å•çš„æ¢¯åº¦ä¸‹é™ã€‚ | ä½ã€‚å®¹æ˜“å‘æ•£ï¼Œéœ€è¦å¤æ‚çš„è¶…å‚æ§åˆ¶ã€‚ |

## å…³é”®é…ç½®è§£è¯»

| å‚æ•° | å»ºè®®å€¼ | åŸç†è§£è¯» |
| :--- | :--- | :--- |
| `learning_rate` | `1e-4` æˆ– `5e-5` | ç›¸æ¯” RLï¼ŒSFT ä½¿ç”¨è¾ƒé«˜çš„å­¦ä¹ ç‡ä»¥å¿«é€Ÿå­¦ä¹ ä»»åŠ¡æ¨¡å¼ã€‚ |
| `cutoff_len` | `1024` | å†³å®šäº†æ¨¡å‹å•æ¬¡èƒ½å¤„ç†çš„é—®é¢˜+ç­”æ¡ˆçš„æ€»é•¿åº¦ã€‚ |
| `lora_target` | `all` | ä¸ºæ‰€æœ‰çº¿æ€§å±‚æ·»åŠ ä½ç§©é€‚é…å™¨ï¼Œå¯ä»¥åœ¨æå‡æ•ˆæœçš„åŒæ—¶æå¤§èŠ‚çœæ˜¾å­˜ã€‚ |

## ğŸ› ï¸ å·¥ç¨‹å®æˆ˜ï¼šä½¿ç”¨ LLaMA Factory è¿›è¡Œ SFT

[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory) æ˜¯ç›®å‰æœ€æµè¡Œçš„å¼€æºå¾®è°ƒæ¡†æ¶ï¼Œæ”¯æŒ 100+ æ¨¡å‹ã€LoRA/QLoRA/å…¨é‡å¾®è°ƒã€WebUI å¯è§†åŒ–è®­ç»ƒã€‚

### Step 1: ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£… LLaMA Factory
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics]"
```

### Step 2: æ•°æ®é›†å‡†å¤‡

LLaMA Factory ä½¿ç”¨ `data/dataset_info.json` æ³¨å†Œæ•°æ®é›†ã€‚è‡ªå®šä¹‰æ•°æ®é›†åªéœ€ä¸¤æ­¥ï¼š

**2a. å‡†å¤‡ JSONL æ•°æ®æ–‡ä»¶**ï¼ˆAlpaca æ ¼å¼ï¼‰ï¼š

```json
[
  {
    "instruction": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯ Transformer ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚",
    "input": "",
    "output": "Transformer ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention Mechanismï¼‰æ˜¯ä¸€ç§è®©æ¨¡å‹åœ¨å¤„ç†åºåˆ—æ—¶ï¼Œèƒ½å¤ŸåŠ¨æ€å…³æ³¨ä¸åŒä½ç½®ä¿¡æ¯çš„æ–¹æ³•..."
  },
  {
    "instruction": "å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ã€‚",
    "input": "å¤§è¯­è¨€æ¨¡å‹æ­£åœ¨æ”¹å˜äººå·¥æ™ºèƒ½çš„æ ¼å±€ã€‚",
    "output": "Large language models are reshaping the landscape of artificial intelligence."
  }
]
```

**2b. åœ¨ `dataset_info.json` ä¸­æ³¨å†Œ**ï¼š

```json
{
  "my_custom_sft": {
    "file_name": "my_custom_sft.json",
    "columns": {
      "prompt": "instruction",
      "query": "input",
      "response": "output"
    }
  }
}
```

### Step 3: è®­ç»ƒé…ç½®ï¼ˆYAMLï¼‰

åˆ›å»ºè®­ç»ƒé…ç½®æ–‡ä»¶ `examples/train_lora/my_sft.yaml`ï¼š

```yaml
### æ¨¡å‹é…ç½®
model_name_or_path: Qwen/Qwen2.5-7B           # åŸºåº§æ¨¡å‹ï¼ˆHuggingFace ID æˆ–æœ¬åœ°è·¯å¾„ï¼‰
trust_remote_code: true

### å¾®è°ƒæ–¹å¼
stage: sft                                      # è®­ç»ƒé˜¶æ®µï¼šsft
do_train: true
finetuning_type: lora                           # å¾®è°ƒç±»å‹ï¼šlora / full / freeze

### LoRA è¶…å‚
lora_target: all                                # å¯¹æ‰€æœ‰çº¿æ€§å±‚æ³¨å…¥ LoRA
lora_rank: 64                                   # ç§©è¶Šå¤§ï¼Œè¡¨è¾¾åŠ›è¶Šå¼ºï¼Œä½†æ˜¾å­˜è¶Šå¤š
lora_alpha: 128                                 # ç¼©æ”¾ç³»æ•°ï¼Œé€šå¸¸ä¸º rank çš„ 2 å€
lora_dropout: 0.05

### æ•°æ®é…ç½®
dataset: my_custom_sft                          # å¯¹åº” dataset_info.json ä¸­çš„ key
template: qwen                                  # å¯¹è¯æ¨¡æ¿ï¼ˆqwen / llama3 / chatglm ç­‰ï¼‰
cutoff_len: 2048                                # æœ€å¤§åºåˆ—é•¿åº¦
preprocessing_num_workers: 16

### è®­ç»ƒè¶…å‚
per_device_train_batch_size: 2
gradient_accumulation_steps: 8                  # æœ‰æ•ˆæ‰¹æ¬¡ = 2 Ã— 8 = 16
num_train_epochs: 3.0
learning_rate: 1.0e-4
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true                                      # BF16 æ··åˆç²¾åº¦ï¼ˆA100/H100ï¼‰
gradient_checkpointing: true                    # ç”¨æ—¶é—´æ¢æ˜¾å­˜

### æ—¥å¿—ä¸ä¿å­˜
logging_steps: 10
save_steps: 500
output_dir: saves/qwen2.5-7b/lora/my_sft
report_to: tensorboard
```

### Step 4: å¯åŠ¨è®­ç»ƒ

```bash
# æ–¹å¼ä¸€ï¼šCLI å‘½ä»¤è¡Œå¯åŠ¨ï¼ˆæ¨èï¼‰
llamafactory-cli train examples/train_lora/my_sft.yaml

# æ–¹å¼äºŒï¼šWebUI å¯è§†åŒ–å¯åŠ¨
llamafactory-cli webui
```

> **æ˜¾å­˜ä¼°ç®—**ï¼šQwen2.5-7B + LoRA (rank=64) + BF16 + Gradient Checkpointing â‰ˆ **16~20GB VRAM**ï¼ˆå•å¡ A100/4090 å¯è·‘ï¼‰ã€‚

### Step 5: åˆå¹¶ LoRA æƒé‡

è®­ç»ƒå®Œæˆåï¼ŒLoRA æƒé‡éœ€è¦åˆå¹¶å›åŸºåº§æ¨¡å‹æ‰èƒ½ç‹¬ç«‹éƒ¨ç½²ï¼š

```yaml
# merge_lora.yaml
model_name_or_path: Qwen/Qwen2.5-7B
adapter_name_or_path: saves/qwen2.5-7b/lora/my_sft
template: qwen
finetuning_type: lora
export_dir: models/qwen2.5-7b-sft-merged        # åˆå¹¶åçš„å®Œæ•´æ¨¡å‹è¾“å‡ºè·¯å¾„
export_size: 4                                    # æ¯ä¸ªåˆ†ç‰‡å¤§å° (GB)
export_legacy_format: false
```

```bash
llamafactory-cli export merge_lora.yaml
```

### Step 6: æ¨ç†éªŒè¯

```bash
# å¿«é€Ÿå¯¹è¯æµ‹è¯•ï¼ˆä½¿ç”¨ LoRA é€‚é…å™¨ï¼Œæ— éœ€åˆå¹¶ï¼‰
llamafactory-cli chat examples/train_lora/my_sft.yaml
```

æˆ–ä½¿ç”¨ Python åŠ è½½åˆå¹¶åçš„æ¨¡å‹ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = "models/qwen2.5-7b-sft-merged"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, device_map="auto")

messages = [{"role": "user", "content": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯ LoRA å¾®è°ƒï¼Ÿ"}]
text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer(text, return_tensors="pt").to(model.device)

outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.7, top_p=0.9)
print(tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True))
```

---

## ğŸ”§ è¿›é˜¶ï¼šå¤š GPU / DeepSpeed åˆ†å¸ƒå¼è®­ç»ƒ

```yaml
# åœ¨ YAML ä¸­æ·»åŠ  DeepSpeed é…ç½®
deepspeed: examples/deepspeed/ds_z2_config.json   # ZeRO-2ï¼ˆæ¨è SFTï¼‰
```

```bash
# å¤šå¡å¯åŠ¨
CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train examples/train_lora/my_sft.yaml
```

---

## ğŸ“Š è®­ç»ƒç›‘æ§

```bash
# æŸ¥çœ‹ TensorBoard è®­ç»ƒæ›²çº¿
tensorboard --logdir saves/qwen2.5-7b/lora/my_sft
```

**å…³é”®æŒ‡æ ‡**ï¼š

- `train/loss`ï¼šåº”å¹³æ»‘ä¸‹é™è‡³ 1.0 ä»¥ä¸‹ã€‚
- `eval/loss`ï¼šè‹¥ä¸ train/loss å·®è·æŒç»­å¢å¤§ï¼Œè¯´æ˜**è¿‡æ‹Ÿåˆ**ï¼Œéœ€å‡å°‘ epoch æˆ–å¢åŠ æ•°æ®ã€‚

---

## åŸå§‹è„šæœ¬è¿è¡Œ

æœ¬æ¨¡å—ä¹Ÿæä¾›äº†ä¸ä¾èµ–æ¡†æ¶çš„çº¯ PyTorch SFT å®ç°ï¼Œä¾›ç†è§£åº•å±‚æœºåˆ¶ï¼š

```bash
python code/sft.py
```
