# CUDA ä¸“é¢˜

> [!TIP]
> **ä¸€å¥è¯é€šä¿—ç†è§£**ï¼šç”¨ä½ç²¾åº¦æµ®ç‚¹æ•°ä»£æ›¿ FP32ï¼Œæ˜¾å­˜çœä¸€åŠï¼Œé€Ÿåº¦ç¿»å€ï¼Œæ•ˆæœå‡ ä¹ä¸å˜

## å®šä½ä¸åˆ†ç±»

- **é˜¶æ®µ**ï¼šåº•å±‚çš„è®¡ç®—åŠ é€Ÿï¼ˆHardware Accelerationï¼‰ã€‚
- **ç±»å‹**ï¼šå¹¶è¡Œè®¡ç®—æ¶æ„ä¸ç¼–ç¨‹æ¨¡å‹ã€‚
- **ä½œç”¨**ï¼šCUDA (Compute Unified Device Architecture) æ˜¯ç”± NVIDIA æ¨å‡ºçš„è¿ç®—å¹³å°ã€‚å®ƒè®©å¼€å‘è€…èƒ½å¤Ÿåˆ©ç”¨ GPU çš„æˆåƒä¸Šä¸‡ä¸ªæ ¸å¿ƒæ¥åŠ é€ŸåŸæœ¬åœ¨ CPU ä¸Šè¿è¡Œç¼“æ…¢çš„æ•°å€¼å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚çŸ©é˜µä¹˜æ³•ã€å·ç§¯è¿ç®—ï¼‰ã€‚

## å®šä¹‰ä¸ç›®æ ‡

ç®€å•æ¥è¯´ï¼ŒCUDA æ˜¯æ·±åº¦å­¦ä¹ çš„â€œå¼•æ“â€ã€‚
å¦‚æœè¯´ CPU æ˜¯ä¸€ä½ç²¾é€šå„ç§æ‚æ´»çš„â€œå…¨èƒ½ä¸»ç®¡â€ï¼Œé‚£ä¹ˆ GPU å°±æ˜¯ç”±å‡ åƒååªæ“…é•¿ç®—æ•°çš„â€œè®¡ç®—å‘˜â€ç»„æˆçš„é˜µåˆ—ã€‚CUDA åˆ™æ˜¯è¿™æ”¯é˜µåˆ—çš„**è°ƒåº¦æ‰‹å†Œ**ï¼Œå®ƒè´Ÿè´£å‘è¿™äº›è®¡ç®—å‘˜åˆ†æ´¾ä»»åŠ¡ï¼Œå¹¶æ”¶é›†ä»–ä»¬çš„è®¡ç®—ç»“æœã€‚

## å…³é”®æ­¥éª¤

1. **Host-to-Device æ•°æ®æ‹·è´**ï¼š
   - å°†å†…å­˜ï¼ˆCPUï¼‰ä¸­çš„æ•°æ®é€šè¿‡ PCIe æ€»çº¿æ‹·è´åˆ°æ˜¾å­˜ï¼ˆGPUï¼‰ã€‚
2. **æ ¸å‡½æ•° (Kernel) å¯åŠ¨**ï¼š
   - å®šä¹‰è®¡ç®—é€»è¾‘å¹¶æŒ‡å®š**æ‰§è¡Œé…ç½® (Execution Configuration)**ï¼Œå³å¯åŠ¨å¤šå°‘ä¸ªçº¿ç¨‹å— (Blocks) å’Œæ¯ä¸ªå—å¤šå°‘ä¸ªçº¿ç¨‹ (Threads)ã€‚
3. **å¹¶è¡Œè®¡ç®—æ‰§è¡Œ**ï¼š
   - GPU ä¸Šçš„å¤§é‡æ ¸å¿ƒåŒæ—¶æ‰§è¡Œç›¸åŒçš„æŒ‡ä»¤ï¼Œä½†å¤„ç†ä¸åŒçš„æ•°æ®åˆ†ç‰‡ (SIMT)ã€‚
4. **Device-to-Host æ•°æ®å›ä¼ **ï¼š
   - å°† GPU è®¡ç®—å¥½çš„ç»“æœæ‹·è´å› CPU å†…å­˜ä¾›åç»­å¤„ç†ã€‚

## æ ¸å¿ƒå†…å­˜æ¶æ„

### 1. çº¿ç¨‹åˆ†å±‚æ¨¡å‹

- **Grid (ç½‘æ ¼)**ï¼šä¸€æ¬¡æ ¸å‡½æ•°å¯åŠ¨çš„æ€»è§„æ¨¡ã€‚
- **Block (çº¿ç¨‹å—)**ï¼šä¸€ç»„å¯ä»¥å…±äº«å†…å­˜å¹¶è¿›è¡ŒåŒæ­¥çš„çº¿ç¨‹ã€‚
- **Thread (çº¿ç¨‹)**ï¼šæ‰§è¡Œè®¡ç®—çš„æœ€å°å•å…ƒã€‚

### 2. å­˜å‚¨åˆ†å±‚ (Memory Hierarchy)

- **Global Memory (å…¨å±€æ˜¾å­˜)**ï¼šå®¹é‡å¤§ä½†å»¶è¿Ÿé«˜ï¼Œæ‰€æœ‰çº¿ç¨‹å¯è§ã€‚
- **Shared Memory (å…±äº«å†…å­˜)**ï¼šå®¹é‡æå°ä½†é€Ÿåº¦æå¿«ï¼ŒåŒä¸€ä¸ª Block å†…éƒ¨çš„çº¿ç¨‹å¯è§ï¼Œå¸¸ç”¨äºä¼˜åŒ–å¸¦å®½ã€‚
- **Registers (å¯„å­˜å™¨)**ï¼šæœ€å¿«çš„å­˜å‚¨ï¼Œæ¯ä¸ªçº¿ç¨‹ç‹¬å ã€‚

## ä¸ç›¸è¿‘æ–¹æ³•åŒºåˆ«

1. ç›¸æ¯” `mixed_precision`ï¼šCUDA å…³æ³¨è®¾å¤‡ä¸ç®—å­ï¼Œæ··åˆç²¾åº¦å…³æ³¨æ•°å€¼æ ¼å¼ã€‚
2. ç›¸æ¯” `DeepSpeed`ï¼šCUDA æ˜¯åº•å±‚æ‰§è¡Œå±‚ï¼ŒDeepSpeed æ˜¯ä¸Šå±‚ç³»ç»Ÿä¼˜åŒ–ã€‚
3. ç›¸æ¯”ç®—æ³•æ¨¡å—ï¼šCUDA ä¸æ”¹å˜å­¦ä¹ ç›®æ ‡ï¼Œä»…å½±å“è®­ç»ƒæ•ˆç‡ã€‚

## ğŸ› ï¸ å·¥ç¨‹å®æˆ˜

### Triton Kernel ç¼–å†™ï¼ˆæ¨èå…¥é—¨æ–¹å¼ï¼‰

Triton æ˜¯ OpenAI å¼€æºçš„ GPU ç¼–ç¨‹è¯­è¨€ï¼Œæ¯”åŸç”Ÿ CUDA C æ›´æ˜“ä¸Šæ‰‹ï¼š

```python
import triton
import triton.language as tl
import torch

@triton.jit
def vector_add_kernel(
    x_ptr, y_ptr, output_ptr,
    n_elements,
    BLOCK_SIZE: tl.constexpr,
):
    """GPU å¹¶è¡Œå‘é‡åŠ æ³• Kernel"""
    pid = tl.program_id(0)                          # å½“å‰çº¿ç¨‹å— ID
    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)  # æ¯ä¸ªçº¿ç¨‹è´Ÿè´£çš„å…ƒç´ ç´¢å¼•
    mask = offsets < n_elements                       # è¾¹ç•Œæ£€æŸ¥

    x = tl.load(x_ptr + offsets, mask=mask)
    y = tl.load(y_ptr + offsets, mask=mask)
    tl.store(output_ptr + offsets, x + y, mask=mask)

# è°ƒç”¨
def vector_add(x: torch.Tensor, y: torch.Tensor):
    output = torch.empty_like(x)
    n = x.numel()
    grid = lambda meta: (triton.cdiv(n, meta["BLOCK_SIZE"]),)
    vector_add_kernel[grid](x, y, output, n, BLOCK_SIZE=1024)
    return output

x = torch.randn(10000, device="cuda")
y = torch.randn(10000, device="cuda")
result = vector_add(x, y)
```

### PyTorch è‡ªå®šä¹‰ CUDA Extension

```python
# ä½¿ç”¨ torch.utils.cpp_extension ç¼–è¯‘è‡ªå®šä¹‰ç®—å­
from torch.utils.cpp_extension import load_inline

cuda_source = """
__global__ void relu_kernel(float* x, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        x[idx] = fmaxf(x[idx], 0.0f);
    }
}

torch::Tensor custom_relu(torch::Tensor x) {
    int n = x.numel();
    int threads = 256;
    int blocks = (n + threads - 1) / threads;
    relu_kernel<<<blocks, threads>>>(x.data_ptr<float>(), n);
    return x;
}
"""

custom_ops = load_inline(
    name="custom_ops",
    cpp_sources="torch::Tensor custom_relu(torch::Tensor x);",
    cuda_sources=cuda_source,
    functions=["custom_relu"],
)

x = torch.randn(1000, device="cuda")
result = custom_ops.custom_relu(x)  # è‡ªå®šä¹‰ CUDA ReLU
```

### GPU æ€§èƒ½åˆ†æ

```python
# PyTorch Profiler
with torch.profiler.profile(
    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],
    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3),
    on_trace_ready=torch.profiler.tensorboard_trace_handler("./profiler_logs"),
) as prof:
    for step, batch in enumerate(dataloader):
        output = model(batch)
        loss = criterion(output, labels)
        loss.backward()
        optimizer.step()
        prof.step()
```

```python
# å…³é”®æ­¥éª¤ä»£ç ï¼ˆç¤ºæ„ï¼‰
state = init_state()
for step in range(num_steps):
    state = step_update(state)
metrics = evaluate(state)
```

---
## å…³é”®å…¬å¼ï¼ˆé€»è¾‘è¡¨è¾¾ï¼‰

\[
\text{Result} = \text{Core Method}(\text{Input}, \text{Config}, \text{Constraints})
\]

ç¬¦å·è¯´æ˜ï¼š
- \(\text{Input}\)ï¼šä»»åŠ¡è¾“å…¥ã€‚
- \(\text{Config}\)ï¼šè®­ç»ƒæˆ–æ¨ç†é…ç½®ã€‚
- \(\text{Constraints}\)ï¼šæ–¹æ³•çº¦æŸï¼ˆå¦‚èµ„æºã€ç¨³å®šæ€§æˆ–å®‰å…¨è¾¹ç•Œï¼‰ã€‚
## å…³é”®æ­¥éª¤ä»£ç ï¼ˆçº¯æ–‡æ¡£ç¤ºä¾‹ï¼‰

```python
# å…³é”®æµç¨‹ç¤ºæ„ï¼ˆä¸å…·ä½“å·¥ç¨‹å®ç°è§£è€¦ï¼‰
state = init_state()
for step in range(num_steps):
    state = step_update(state)
metrics = evaluate(state)
```
