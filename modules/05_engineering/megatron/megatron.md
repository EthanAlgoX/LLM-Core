# Megatron ä¸“é¢˜

> [!TIP]
> **ä¸€å¥è¯é€šä¿—ç†è§£**ï¼šæ¨¡å‹åˆ‡æ¨ªåˆ€ã€çºµåˆ€ã€æµæ°´çº¿â€”â€”ä¸‰æŠŠåˆ€è§£å†³è¶…å¤§æ¨¡å‹çš„åˆ†å¸ƒå¼è®­ç»ƒéš¾é¢˜

## å®šä½ä¸åˆ†ç±»

- **é˜¶æ®µ**ï¼šå¤§è§„æ¨¡é¢„è®­ç»ƒç³»ç»Ÿï¼ˆTraining Systemsï¼‰ã€‚
- **ç±»å‹**ï¼šå¤§è§„æ¨¡åˆ†å¸ƒå¼å¹¶è¡Œæ¡†æ¶ã€‚
- **ä½œç”¨**ï¼šMegatron-LM æ˜¯ NVIDIA å¼€å‘çš„æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œä¸“é—¨ä¸ºè®­ç»ƒè¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ GPT-3, GPT-4ï¼‰è®¾è®¡ã€‚å®ƒè§£å†³äº†å•å¼  GPU æ˜¾å­˜ä¸è¶³ä»¥å®¹çº³ç™¾äº¿ç”šè‡³åƒäº¿å‚æ•°æ¨¡å‹çš„ç—›ç‚¹ã€‚

## ä»€ä¹ˆæ˜¯ Megatronï¼Ÿ

Megatron æ˜¯åˆ†å¸ƒå¼å¹¶è¡Œè®­ç»ƒçš„â€œé›†å¤§æˆè€…â€ã€‚
å½“ä¸€ä¸ªæ¨¡å‹å¤ªå¤§ï¼Œä¸€å¼ æ˜¾å¡å¡ä¸ä¸‹æ—¶ï¼ŒMegatron æä¾›äº†å¤šç§åˆ‡åˆ†æ‰‹æ®µï¼šå®ƒå¯ä»¥æŠŠä¸€ä¸ªçŸ©é˜µè¿ç®—æ‹†åˆ°å¤šå¼ å¡ä¸Šè·‘ï¼ˆå¼ é‡å¹¶è¡Œï¼‰ï¼Œä¹Ÿå¯ä»¥æŠŠæ¨¡å‹çš„ä¸åŒå±‚æ‹†åˆ°ä¸åŒå¡ä¸Šï¼ˆæµæ°´çº¿å¹¶è¡Œï¼‰ã€‚

## å…³é”®å¹¶è¡Œæ­¥éª¤

1. **å¼ é‡å¹¶è¡Œ (Tensor Parallelism, TP)**ï¼š
   - å°†å•ä¸ª Transformer å±‚å†…çš„çŸ©é˜µä¹˜æ³•è¿›è¡Œå¹¶è¡ŒåŒ–ã€‚ä¾‹å¦‚ï¼Œå°† Attention çš„å¤šå¤´æˆ– MLP çš„ç¥ç»å…ƒæ‹†åˆ†åˆ°å¤šå¼  GPU ä¸Šã€‚
2. **æµæ°´çº¿å¹¶è¡Œ (Pipeline Parallelism, PP)**ï¼š
   - å°†æ¨¡å‹çš„å±‚åˆ†ä¸ºä¸åŒçš„â€œæ®µâ€ï¼ˆStagesï¼‰ï¼Œæ¯å¼  GPU æˆ–æ¯ç»„ GPU è´Ÿè´£ä¸€æ®µã€‚æ•°æ®åƒæµæ°´çº¿ä¸€æ ·åœ¨æ®µé—´ä¼ é€’ã€‚
3. **æ•°æ®å¹¶è¡Œ (Data Parallelism, DP)**ï¼š
   - åœ¨ TP å’Œ PP çš„åŸºç¡€ä¸Šï¼Œå¤åˆ¶æ•´ä¸ªæ¨¡å‹å¹¶è¡Œå¤„ç†ä¸åŒçš„æ•°æ®é›†ã€‚
4. **ä¸“å®¶å¹¶è¡Œ (Expert Parallelism, EP)**ï¼š
   - ä¸“é—¨ç”¨äº **MoE æ¨¡å‹**ã€‚å°†ä¸åŒçš„ä¸“å®¶åˆ†å¸ƒåœ¨ä¸åŒçš„è®¾å¤‡ä¸Šï¼Œé…åˆ **All-to-All** é€šä¿¡æœºåˆ¶ï¼Œæ˜¾è‘—é™ä½å•å¡æ˜¾å­˜å‹åŠ›ã€‚
5. **åˆ†å¸ƒå¼åˆå§‹åŒ– (Initialization)**ï¼š
   - é…ç½® `world_size` ä»¥åŠ TP/PP/DP/EP çš„åˆ†ç»„ï¼Œå»ºç«‹è¿›ç¨‹é—´çš„é€šä¿¡ã€‚

## æ ¸å¿ƒæ•°å­¦å…¬å¼

### 1. é€šä¿¡ç»„å¤§å°è®¡ç®—

$$WorldSize = TP_{size} \times PP_{size} \times DP_{size} \times EP_{size}$$

- è¿™ä¸€å…¬å¼å®šä¹‰äº†å®Œæˆä¸€ä¸ªå®Œæ•´å‰å‘+åå‘è¿‡ç¨‹æ‰€éœ€çš„æ€» GPU æ•°é‡ã€‚åœ¨ MoE æ¨¡å‹ä¸­ï¼ŒEP åˆ†ç»„å¤§å°é€šå¸¸ç­‰äºä¸“å®¶æ•°é‡ï¼ˆæˆ–å…¶å€æ•°ï¼‰ã€‚

### 2. æ¢¯åº¦ç´¯åŠ æ­¥æ•° (Gradient Accumulation)

ä¸ºäº†åŒ¹é…ç¡¬ä»¶ç®—åŠ›ä¸ç›®æ ‡ Batch Sizeï¼š

$$GradAccum = \frac{GlobalBatchSize}{MicroBatchSize \times DP_{size}}$$

- **Micro Batch Size**ï¼šå•å¼ å¡ä¸€æ¬¡è¯»å…¥çš„æ•°æ®é‡ã€‚
- **Global Batch Size**ï¼šæ›´æ–°ä¸€æ¬¡æƒé‡æ‰€åŸºäºçš„æ€»æ•°æ®é‡ã€‚

## ä¸ç›¸è¿‘æ–¹æ³•åŒºåˆ«

1. ç›¸æ¯” `nanoGPT`ï¼šMegatron æ›´ååˆ†å¸ƒå¼å·¥ç¨‹ï¼Œä¸æ˜¯æœ€å°æ•™å­¦å®ç°ã€‚
2. ç›¸æ¯” `DeepSpeed`ï¼šMegatronåæ¨¡å‹å¹¶è¡Œï¼ŒDeepSpeedå ZeRO ä¸ç³»ç»Ÿä¼˜åŒ–ã€‚
3. ç›¸æ¯” `mixed_precision`ï¼šå¹¶è¡Œç­–ç•¥è§£å†³è§„æ¨¡é—®é¢˜ï¼Œç²¾åº¦ç­–ç•¥è§£å†³æ•ˆç‡é—®é¢˜ã€‚

## ğŸ› ï¸ å·¥ç¨‹å®æˆ˜

### Megatron-LM é¢„è®­ç»ƒå¯åŠ¨

```bash
# å…³é”®å‚æ•°ï¼š3D å¹¶è¡Œé…ç½®
TENSOR_PARALLEL=4          # TP: åŒèŠ‚ç‚¹å†… NVLink äº’è”çš„å¡æ•°
PIPELINE_PARALLEL=2        # PP: è·¨èŠ‚ç‚¹çš„æµæ°´çº¿æ®µæ•°
DATA_PARALLEL=2            # DP: è‡ªåŠ¨è®¡ç®— = WORLD_SIZE / (TP Ã— PP)
WORLD_SIZE=16              # æ€» GPU æ•° = 4 Ã— 2 Ã— 2
TRAIN_ENTRY="<megatron_training_entry>"  # è®­ç»ƒå…¥å£å ä½ç¬¦ï¼ˆç”±ä½ è‡ªå·±çš„å¤–éƒ¨å·¥ç¨‹æä¾›ï¼‰

# å¯åŠ¨ Megatron-LM GPT é¢„è®­ç»ƒï¼ˆçº¯æ–‡æ¡£ç¤ºä¾‹ï¼šå±•ç¤ºå…³é”®å‚æ•°ç»„åˆï¼‰
torchrun --nproc_per_node=4 --nnodes=4 --node_rank=$NODE_RANK \
    --master_addr=$MASTER_ADDR --master_port=6000 \
    "$TRAIN_ENTRY" \
    --tensor-model-parallel-size $TENSOR_PARALLEL \
    --pipeline-model-parallel-size $PIPELINE_PARALLEL \
    --num-layers 32 \
    --hidden-size 4096 \
    --num-attention-heads 32 \
    --seq-length 4096 \
    --max-position-embeddings 4096 \
    --micro-batch-size 1 \
    --global-batch-size 64 \
    --lr 1.5e-4 \
    --min-lr 1.5e-5 \
    --lr-decay-style cosine \
    --train-iters 100000 \
    --bf16 \
    --data-path my_dataset_text_document \
    --tokenizer-type HFTokenizer \
    --tokenizer-model Qwen/Qwen2.5-7B \
    --save checkpoints/megatron_gpt \
    --save-interval 1000 \
    --log-interval 10
```

### Megatron + DeepSpeed è”åˆè®­ç»ƒ

```bash
# ç»“åˆ Megatron çš„æ¨¡å‹å¹¶è¡Œ + DeepSpeed çš„ ZeRO ä¼˜åŒ–
TRAIN_ENTRY="<megatron_training_entry>"  # è®­ç»ƒå…¥å£å ä½ç¬¦ï¼ˆç”±ä½ è‡ªå·±çš„å¤–éƒ¨å·¥ç¨‹æä¾›ï¼‰
deepspeed --num_gpus=8 "$TRAIN_ENTRY" \
    --tensor-model-parallel-size 4 \
    --pipeline-model-parallel-size 2 \
    --deepspeed \
    --deepspeed_config ds_config.json \
    --zero-stage 1 \
    --bf16
```

### PyTorch å±‚é¢ç†è§£ TP åˆ‡åˆ†

```python
import torch
import torch.distributed as dist

# å¼ é‡å¹¶è¡Œæ ¸å¿ƒï¼šåˆ—åˆ‡åˆ† Linear
class ColumnParallelLinear(torch.nn.Module):
    """å°† Linear çš„è¾“å‡ºç»´åº¦æŒ‰ TP åˆ†åˆ°ä¸åŒ GPU"""
    def __init__(self, in_features, out_features, tp_size):
        super().__init__()
        self.tp_size = tp_size
        self.out_per_partition = out_features // tp_size
        self.weight = torch.nn.Parameter(
            torch.randn(self.out_per_partition, in_features)
        )

    def forward(self, x):
        # æ¯å¼ å¡åªè®¡ç®— out_features / tp_size åˆ—
        output = torch.nn.functional.linear(x, self.weight)
        return output  # åç»­é€šè¿‡ AllReduce æ±‡æ€»

# ç¤ºä¾‹ï¼š4096 â†’ 16384 çš„ MLPï¼Œ4 å¡ TP
# æ¯å¡åªå­˜ 4096 â†’ 4096 çš„æƒé‡ï¼ˆ1/4ï¼‰
mlp = ColumnParallelLinear(4096, 16384, tp_size=4)
```

---

## åŸå§‹è„šæœ¬è¿è¡Œ

```bash
cd <YOUR_PROJECT_ROOT>/pre_train/llm/megatron
conda activate finetune
# çº¯æ–‡æ¡£ä»“åº“ï¼šå†å²è„šæœ¬å‘½ä»¤å·²å½’æ¡£
```
